{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af1a5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import urllib3\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d729bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3992b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for getting  stopwords \n",
    "#stopwords taken from  https://sraf.nd.edu/textual-analysis/resources/ \n",
    "\n",
    "def stopwords_list():\n",
    "    stop_words=set()\n",
    "    with open('StopWords_Generic.txt','r') as f:\n",
    "        for line in f:\n",
    "            stop_words.add(line.strip().lower())\n",
    "    #print('STOPWORDS ARE ', stop_words)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b10e4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using LoughranMcDonald_MasterDictionary_2020 of words\n",
    "#dict link https://sraf.nd.edu/textual-analysis/resources/ \n",
    "if not os.path.isdir('dicts'):\n",
    "    os.mkdir('dicts')\n",
    "def dictinoaries():\n",
    "    \n",
    "    stop_words=stopwords_list()\n",
    "    pos_neg_dict=pd.read_csv('LoughranMcDonald_MasterDictionary_2020.csv')\n",
    "    pos_neg_dict['Word']=pos_neg_dict['Word'].apply(lambda row:str(row).lower()) #words to lower\n",
    "    cstm_pos_dict={}\n",
    "    cstm_neg_dict={}\n",
    "    with open('dicts//neg_dict.txt','w') as f:\n",
    "        for word,score in zip(pos_neg_dict['Word'],pos_neg_dict['Negative']):\n",
    "            if word not in stop_words and score!=0:\n",
    "                cstm_neg_dict[word]=-1\n",
    "                f.write(word+'\\n')\n",
    "            \n",
    "            \n",
    "    with open('dicts//pos_dict.txt','w') as f:\n",
    "        for word,score in zip(pos_neg_dict['Word'],pos_neg_dict['Positive']):\n",
    "            if word not in stop_words and score!=0:\n",
    "                cstm_pos_dict[word]=+1\n",
    "                f.write(word+'\\n')\n",
    "    return cstm_neg_dict,cstm_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract positive words from the text which are in the dict and not in the stop words list\n",
    "#and calculating positive and negative score\n",
    "def extraction(text):\n",
    "    text=text.lower()\n",
    "    #dictinoary\n",
    "    cstm_neg_dict,cstm_pos_dict=dictinoaries()\n",
    "    #stopwords\n",
    "    stop_words=stopwords_list()\n",
    "    tokenizer=nltk.RegexpTokenizer('\\w+')\n",
    "    #from nltk.tokenize import word_tokenize   #also includes . ? etc\n",
    "    token_text=tokenizer.tokenize(text)\n",
    "    #token_text=word_tokenize(text)\n",
    "    pos_score_dict={}\n",
    "    for word in token_text:\n",
    "         if word not in stop_words and word in cstm_pos_dict:\n",
    "                print('word is',word)\n",
    "                if word not in pos_score_dict:\n",
    "                    pos_score_dict[word]=1\n",
    "                else:\n",
    "                    pos_score_dict[word]+=1\n",
    "                \n",
    "    \n",
    "    #negtive_score\n",
    "    neg_score_dict={}\n",
    "    for word in token_text:\n",
    "         if word not in stop_words and word in cstm_neg_dict:\n",
    "                if word not in neg_score_dict:\n",
    "                    neg_score_dict[word]=-1\n",
    "                else:\n",
    "                    neg_score_dict[word]-=1\n",
    "                \n",
    "    \n",
    "    text_pos_score =0\n",
    "    text_neg_score=0\n",
    "    #adding all the scores\n",
    "    text_pos_score=sum(pos_score_dict.values())\n",
    "    text_neg_score=sum(neg_score_dict.values())*-1\n",
    "    \n",
    "    #POLARITY SCORE\n",
    "    text_polarity_score=(text_pos_score-text_neg_score)/((text_pos_score + text_neg_score) + 0.000001)\n",
    "    \n",
    "    #Subjectivity Score: \n",
    "    clean_text=[word for word in token_text if word not in stop_words]\n",
    "    #print('clean_text ',len(clean_text))\n",
    "    #a=' '.join(str(word) for word in clean_text) in str spaces are also counted in len\n",
    "    \n",
    "    subjectivity_score=(text_pos_score + text_neg_score)/(len(clean_text)+ 0.000001)\n",
    "    #print('subjectivity_score', subjectivity_score)\n",
    "    \n",
    "    return text_pos_score,text_neg_score,text_polarity_score,subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c84b0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "   \n",
    "def scrape(iid,link):\n",
    "    \n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',\n",
    "}\n",
    "    html_txt=requests.get(str(link),headers=headers)\n",
    "    \n",
    "    clean_text=BeautifulSoup(html_txt.content,'html.parser')\n",
    "    heading=BeautifulSoup.findAll(clean_text,'h1',attrs={'class':'entry-title'})\n",
    "    #print(heading)\n",
    "    heading=re.sub(r'<.*?>','',str(heading))\n",
    "    heading=heading.strip(\"[]\")\n",
    "    #print(heading)\n",
    "    #paragrapsh\n",
    "    paragraph=BeautifulSoup.findAll(clean_text,'p')\n",
    "    #print(paragraph)\n",
    "    paragraph=re.sub(r'<.*?>','',str(paragraph))\n",
    "    paragraph=paragraph.strip('[]') #[] i the beg and the ending\n",
    "    print(paragraph)\n",
    "    #print(paragraph)\n",
    "    #with open('scraped_files_dummy\\\\'+str(iid)+'.txt','w') as f:\n",
    "        #f.write(heading)\n",
    "        #f.write(paragraph)\n",
    "    text=heading+\" . \"+paragraph\n",
    "    extraction(text)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    return text,text_pos_score,text_neg_score,text_polarity_score,subjectivity_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30ca1b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text=[]\n",
    "text_pos_score=[]\n",
    "text_neg_score=[]\n",
    "text_polarity_score=[]\n",
    "subjectivity_score=[]\n",
    "\n",
    "if not os.path.isdir('scraped_files'):\n",
    "    os.mkdir('scraped_files')\n",
    "for url_id,link in tqdm(zip(data['URL_ID'],data['URL'])):\n",
    "    text_single,text_pos,text_neg,text_polarity,subjectivity=scrape(url_id,link)\n",
    "    text.append(text_single)\n",
    "    text_pos_score.append(text_pos)\n",
    "    text_neg_score.append(text_neg_score)\n",
    "    text_polarity_score.append(text_polarity)\n",
    "    subjectivity_score.append(subjectivity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f795798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['text']=text\n",
    "data['postive']=text_pos_score\n",
    "data['negative']=text_neg_score\n",
    "data['polarity']=text_polarity_score\n",
    "data['subjectivity']=subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee7549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
